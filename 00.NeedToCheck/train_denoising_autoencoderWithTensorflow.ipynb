{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_denoising_autoencoderWithTensorflow.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPctWsjsVI9e+t0yIjMYZZh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"envQu8cV8XUd","colab_type":"text"},"source":["#https://www.pyimagesearch.com/2020/02/17/autoencoders-with-keras-tensorflow-and-deep-learning/"]},{"cell_type":"code","metadata":{"id":"OhdjTI1IzFFl","colab_type":"code","outputId":"b324c185-684a-48b9-9818-152a0b0d690f","executionInfo":{"status":"ok","timestamp":1587357923320,"user_tz":-540,"elapsed":729,"user":{"displayName":"sanghun oh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghlx86owSfLI1ysBzewc-4sBRVA0uQ32rdNEjLr1Q=s64","userId":"06412681606171338922"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import matplotlib\n","matplotlib.use(\"Agg\")\n","\n","# import the necessary packages\n","# from convautoencoder import ConvAutoencoder\n","import os\n","from os import listdir\n","listdir(os.getcwd())"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['.config', 'sample_data']"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"6QqAMNhguWZz","colab_type":"code","outputId":"7c205ed0-8986-4f0d-cf80-df7ad6a5c2b3","executionInfo":{"status":"ok","timestamp":1587357925427,"user_tz":-540,"elapsed":2827,"user":{"displayName":"sanghun oh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghlx86owSfLI1ysBzewc-4sBRVA0uQ32rdNEjLr1Q=s64","userId":"06412681606171338922"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["!pip install convautoencoder"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\u001b[31mERROR: Could not find a version that satisfies the requirement convautoencoder (from versions: none)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for convautoencoder\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"A_dnSxcNzIJG","colab_type":"code","outputId":"4a67a332-3024-49d8-d4a9-53c151b987e9","executionInfo":{"status":"error","timestamp":1587357925430,"user_tz":-540,"elapsed":2827,"user":{"displayName":"sanghun oh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghlx86owSfLI1ysBzewc-4sBRVA0uQ32rdNEjLr1Q=s64","userId":"06412681606171338922"}},"colab":{"base_uri":"https://localhost:8080/","height":388}},"source":["from convautoencoder import ConvAutoencoder\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.datasets import mnist\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import argparse\n","import cv2"],"execution_count":0,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-876ccb56c2f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mconvautoencoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvAutoencoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'convautoencoder'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"Z7vZ92mBzfnW","colab_type":"code","colab":{}},"source":["import easydict \n","system_args = {'output':\"output02.png\", \"plot\":\"plot02.png\", }\n","args = easydict.EasyDict(system_args)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dq7I1InFzi-Z","colab_type":"code","colab":{}},"source":["# initialize the number of epochs to train for and batch size\n","EPOCHS = 1\n","BS = 32\n","\n","# load the MNIST dataset\n","print(\"[INFO] loading MNIST dataset...\")\n","((trainX, _), (testX, _)) = mnist.load_data()\n","\n","# add a channel dimension to every image in the dataset, then scale\n","# the pixel intensities to the range [0, 1]\n","trainX = np.expand_dims(trainX, axis=-1)\n","testX = np.expand_dims(testX, axis=-1)\n","trainX = trainX.astype(\"float32\") / 255.0\n","testX = testX.astype(\"float32\") / 255.0\n","\n","# sample noise from a random normal distribution centered at 0.5 (since\n","# our images lie in the range [0, 1]) and a standard deviation of 0.5\n","trainNoise = np.random.normal(loc=0.5, scale=0.5, size=trainX.shape)\n","testNoise = np.random.normal(loc=0.5, scale=0.5, size=testX.shape)\n","trainXNoisy = np.clip(trainX + trainNoise, 0, 1)\n","testXNoisy = np.clip(testX + testNoise, 0, 1)\n","\n","# construct our convolutional autoencoder\n","print(\"[INFO] building autoencoder...\")\n","(encoder, decoder, autoencoder) = ConvAutoencoder.build(28, 28, 1)\n","opt = Adam(lr=1e-3)\n","autoencoder.compile(loss=\"mse\", optimizer=opt)\n","\n","# train the convolutional autoencoder\n","H = autoencoder.fit(\n","\ttrainXNoisy, trainX,\n","\tvalidation_data=(testXNoisy, testX),\n","\tepochs=EPOCHS,\n","\tbatch_size=BS)\n","\n","# construct a plot that plots and saves the training history\n","N = np.arange(0, EPOCHS)\n","plt.style.use(\"ggplot\")\n","plt.figure()\n","plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n","plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n","plt.title(\"Training Loss and Accuracy\")\n","plt.xlabel(\"Epoch #\")\n","plt.ylabel(\"Loss/Accuracy\")\n","plt.legend(loc=\"lower left\")\n","plt.savefig(args[\"plot\"])\n","\n","# use the convolutional autoencoder to make predictions on the\n","# testing images, then initialize our list of output images\n","print(\"[INFO] making predictions...\")\n","decoded = autoencoder.predict(testXNoisy)\n","outputs = None\n","\n","# loop over our number of output samples\n","for i in range(0, args[\"samples\"]):\n","\t# grab the original image and reconstructed image\n","\toriginal = (testXNoisy[i] * 255).astype(\"uint8\")\n","\trecon = (decoded[i] * 255).astype(\"uint8\")\n","\n","\t# stack the original and reconstructed image side-by-side\n","\toutput = np.hstack([original, recon])\n","\n","\t# if the outputs array is empty, initialize it as the current\n","\t# side-by-side image display\n","\tif outputs is None:\n","\t\toutputs = output\n","\n","\t# otherwise, vertically stack the outputs\n","\telse:\n","\t\toutputs = np.vstack([outputs, output])\n","\n","# save the outputs image to disk\n","cv2.imwrite(args[\"output\"], outputs)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FwjTAjbK0FbO","colab_type":"code","colab":{}},"source":["\n","import pickle\n","denoising_autoencoder_pkl = open( \"denoising_autoencoder.pkl\", \"wb\" )\n","pickle.dump( autoencoder, denoising_autoencoder_pkl)\n","denoising_autoencoder_pkl.close()\n"],"execution_count":0,"outputs":[]}]}